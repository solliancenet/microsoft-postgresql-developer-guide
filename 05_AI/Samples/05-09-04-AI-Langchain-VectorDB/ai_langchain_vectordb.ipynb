{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL as Vector Database with LangChain\n",
    "\n",
    "In this lab you will utilize the built in Document Loading capabilities of LangChain to embed documents into PostgreSQL.\n",
    "\n",
    "You will then use a similarity search to search the indexed and embedded documents followed by using a query Retriever to add context to an Open AI request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install psycopg2\n",
    "!pip install tiktoken\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary modules and types, create a database connection string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "from typing import List, Tuple\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "#depening on your langchain version...\n",
    "#from langchain_community.document_loaders import TextLoader\n",
    "#from langchain_community.document_loaders import PdfLoader\n",
    "#from langchain_community.vectorstores import PGEmbedding\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.document_loaders import UnstructuredXMLLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.vectorstores.pgvector import DistanceStrategy\n",
    "\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database and register the vector extension. Be sure to replace the `SUFFIX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'wsuser'\n",
    "password = 'Solliance123'\n",
    "host = 'pgsqldevuguksx7rflex14.postgres.database.azure.com'\n",
    "port = '5432'\n",
    "dbname = 'ailabs'\n",
    "\n",
    "connection_string = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbconn = psycopg2.connect(host=host, user=username, password=password,\n",
    "    port=port, database=dbname , connect_timeout=10)\n",
    "dbconn.set_session(autocommit=True)\n",
    "\n",
    "cur = dbconn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "register_vector(dbconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI Studio\n",
    "\n",
    "## GPT Text Embeddings\n",
    "\n",
    "Now that you have deployed a simple model via Azure Machine Learning Studio, let's look at redo-ing our embeddings using a different embedding model called `text-embedding-ada-002`.\n",
    "\n",
    "This model is not deployed via Azure Machine Learning Studio, but is a part of Azure OpenAI.\n",
    "\n",
    "- Open the Azure Portal\n",
    "- Search for **Azure Open AI**\n",
    "- Under **Resource Management**, select **Keys and Endpoint**\n",
    "- Record the endpoing and the key\n",
    "- Under **Resource Management**, select **Model deployments**\n",
    "- Select **Manage Delopments**\n",
    "- Select **Create new deployment**\n",
    "- Select the **text-embedding-ada-002** model\n",
    "- For the deployment name, type **embeddings**\n",
    "- Select **Create**\n",
    "- Once the model is deployed, run the following cells to regenerate your embeddings. Be sure to replace the endpoint and key with the ones you just recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the openai embeddings\n",
    "embedding_model = \"embeddings\" #this is the name of the model deployment in azure open ai (not the type of model)\n",
    "\n",
    "azure_endpoint = \"YOUR_API_URL\"  #https://your-endpoing.openai.azure.com/\n",
    "azure_key = 'YOUR_API_KEY'\n",
    "\n",
    "azure_endpoint = \"https://pgsqldevuguksx7r2.openai.azure.com/\"  #https://your-endpoing.openai.azure.com/\n",
    "azure_key = '4358bd337d834ed492561bcd20851c81'\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "                deployment=embedding_model,\n",
    "                openai_api_base=azure_endpoint,\n",
    "                openai_api_key=azure_key,\n",
    "                openai_api_type=\"azure\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a logging handler to output Langchain logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logFormatter = logging.Formatter(\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\")\n",
    "rootLogger = logging.getLogger()\n",
    "\n",
    "logPath = \"./logs\"\n",
    "fileName = \"langchain\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(logPath)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "fileHandler = logging.FileHandler(\"{0}/{1}.log\".format(logPath, fileName))\n",
    "fileHandler.setFormatter(logFormatter)\n",
    "rootLogger.addHandler(fileHandler)\n",
    "\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setFormatter(logFormatter)\n",
    "rootLogger.addHandler(consoleHandler)\n",
    "\n",
    "rootLogger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create method to insert documents to PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_document(db, doc, collection_id):\n",
    "\n",
    "    import uuid\n",
    "\n",
    "    #generate the embeddings\n",
    "    doc_embeddings = embeddings.embed_documents(doc.page_content)\n",
    "\n",
    "    #insert with manual sql\n",
    "    sql = \"INSERT INTO langchain_pg_embedding (collection_id, embedding, document, cmetadata, custom_id, uuid) VALUES ({0},ARRAY {1}, {2}, {3},{4}, {5})\".format(collection_id, doc_embeddings, doc.page_content, None, None, uuid.uuid4())\n",
    "    \n",
    "    cur.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LangChain and PyPDF to split a document apart and then  PGVector to insert the embeddings into PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./data/azure_openai_infographic.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "collection_name = \"open_ai_pdf\"\n",
    "\n",
    "db = PGVector(\n",
    "    collection_name=collection_name,\n",
    "    connection_string=connection_string,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new vector database object from the previous objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_db = db.from_documents(\n",
    "    documents= docs,\n",
    "    embedding = embeddings,\n",
    "    collection_name= collection_name,\n",
    "    distance_strategy = DistanceStrategy.COSINE,\n",
    "    connection_string=connection_string,\n",
    "    logger=rootLogger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a query against the database using simple query.  This will return matching results, but not perform any type of OpenAI completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilize a simple similarity search\n",
    "query = \"Azure OpenAI\"\n",
    "\n",
    "docs_with_score: List[Tuple[Document, float]] = pdf_db.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the earnings transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the text loader and splitter to break apart the document into chunks\n",
    "loader = TextLoader(\"./data/msft_earnings_call_transcript.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "collection_name = \"msft_earnings\"\n",
    "\n",
    "db = PGVector(\n",
    "    collection_name=collection_name,\n",
    "    connection_string=connection_string,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "#Full database load with the creation of the collection and the embedding table.\n",
    "msft_db = db.from_documents(\n",
    "    documents= docs,\n",
    "    embedding = embeddings,\n",
    "    collection_name= collection_name,\n",
    "    distance_strategy = DistanceStrategy.COSINE,\n",
    "    connection_string=connection_string)\n",
    "\n",
    "#You can also manually import the documents into a target collection\n",
    "#for i in range(0, len(docs), 1):\n",
    "#    temp_docs = docs[i:i+1]\n",
    "#    msft_db.add_documents( documents=temp_docs, collection_name=collection_name, connection_string=connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory.buffer import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure a retriever, setup a prompt, the LLM and then create the LLM Chain.  Then execute the Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilize a query retriver\n",
    "prompt_prefix = \"You are a question and answering system. You are given a question and a context. You must answer the question based on the context provided. {context} Question: {question}\"\n",
    "\n",
    "deployment_name = \"your_deployment_name\" #completions4\n",
    "api_version = \"your_api_version\" #2024-02-15-preview\n",
    "model_version = \"your_model_version\"  #0125-Preview\n",
    "\n",
    "retriever = msft_db.as_retriever()\n",
    "\n",
    "#create a simple QA chain\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_prefix,\n",
    "    input_variables=[\"context\", \"question\",  \"chat_history\"], #\"summaries\", \"question\"\n",
    ")\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=deployment_name,\n",
    "                        temperature=0,\n",
    "                        openai_api_base=azure_endpoint,\n",
    "                        openai_api_key=azure_key,\n",
    "                        openai_api_type=\"azure\",\n",
    "                        openai_api_version=api_version,\n",
    "                        model_version=model_version)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"question\"\n",
    "        )\n",
    "\n",
    "llm_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    memory=memory,\n",
    "    #callbacks = [self.handler],\n",
    "    chain_type=\"stuff\",\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask the GPT model a question and get display the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which analysts were on the call?\"\n",
    "\n",
    "answer = llm_chain.invoke(question, return_only_outputs=True)['answer']\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
