{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Virtual Environment\n",
    "\n",
    "It is a best practice to create and activate a new Virtual environment when working with lab samples.  This helps to not overwrite the global settings of your main Python install or overwrite packages across your projects.\n",
    "\n",
    "NOTE: These notebooks were tested with Python 3.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary libraries to your Python environment.  It is a best practice to create a virtual environment to run these samples.  NOTE: these take ~10-15 mins to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2\n",
    "!pip install pgvector\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers\n",
    "!pip install scikit-image\n",
    "!pip install azure-ai-translation-text\n",
    "!pip install matplotlib\n",
    "!pip install azureml-sdk\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import any modules, functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import json\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loading Sentence Transformers\n",
    "\n",
    "Use the following cell to test if your install worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate the data\n",
    "\n",
    "Here you will use the Translation API to convert the source data into English and then save it to a file.\n",
    "\n",
    "Update the translate api key and region to the one created in the deployment/setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import json\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential   \n",
    "from azure.ai.translation.text import TextTranslationClient, TranslatorCredential\n",
    "from azure.ai.translation.text.models import InputTextItem\n",
    "\n",
    "filename = 'metadata.json'\n",
    "translated_filename = 'metadata_translated.json'\n",
    "\n",
    "translate_api_key  = 'YOUR_API_KEY'\n",
    "translate_api_region = 'YOUR_REGION'\n",
    "\n",
    "#if you would like to start from scratch, run this function\n",
    "def download_and_translate():\n",
    "    #download the data...\n",
    "    download_metadata('https://raw.githubusercontent.com/zalandoresearch/feidegger/master/data/FEIDEGGER_release_1.2.json')\n",
    "\n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    #translate the data\n",
    "    for item in data:\n",
    "        descriptions = []\n",
    "        for description in item['descriptions']:\n",
    "            descriptions.append(translate(description, 'de', 'en'))\n",
    "        item['descriptions'] = descriptions\n",
    "\n",
    "    #save the translated data\n",
    "    with open('metadata_translated.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    \n",
    "def download_metadata(url):\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "def translate(text, source_language, target_language):\n",
    "    try:\n",
    "        text_translator = TextTranslationClient(credential = TranslatorCredential(translate_api_key, translate_api_region))\n",
    "        input_text_elements = [ InputTextItem(text = text) ]\n",
    "        response = text_translator.translate(content = input_text_elements, to = [target_language], from_parameter = source_language)\n",
    "        translation = response[0] if response else None\n",
    "        if translation:\n",
    "            for translated_text in translation.translations:\n",
    "                return translated_text.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate the file\n",
    "\n",
    "The translated file has already been provided as part of the repo, if you would like to translate to a different language, you can uncomment the following and execute the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_and_translate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the translated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(translated_filename) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enable Extensions\n",
    "\n",
    "- Browse to the Azure Portal\n",
    "- Browse to the `pgsqldevSUFFIXflex16` Azure Database for PostgreSQL Flexible Server\n",
    "- Under Settings, select **Server parameters**\n",
    "- Search for **azure.extensions**\n",
    "- Set the `azure.extensions` to enable `vector` and `azure_ai` and `azure_storage`\n",
    "- Select **Save**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will create a connection to the server and then register pgvector. If you get a connection error, be sure that a firewall rule has been added for your client IP. Be sure to replace the `SUFFIX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbhost = 'pgsqldevSUFFIXflex16.postgres.database.azure.com'\n",
    "dbport = '5432'\n",
    "dbuser = 'wsuser'\n",
    "dbpass = 'Solliance123'\n",
    "dbname = 'products'\n",
    "\n",
    "dbconn = psycopg2.connect(host=dbhost, user=dbuser, password=dbpass,\n",
    "    port=dbport, database=dbname , connect_timeout=10)\n",
    "dbconn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will take ~8-10mins to execute...\n",
    "cur = dbconn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "register_vector(dbconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode method\n",
    "\n",
    "This method is used to encode a set of sentences using the Hugging Face transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "def encode_sentence(sentences):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(sentences)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings\n",
    "\n",
    "This method is used to generate wrap calling the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data):\n",
    "    r = {}\n",
    "    r['url'] = data['url']\n",
    "    r['descriptions'] = data['descriptions']\n",
    "    r['split'] = data['split']\n",
    "    vector = encode_sentence(data['descriptions'])\n",
    "    r['descriptions_embeddings'] = vector\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table\n",
    "\n",
    "Create a products table for storing the information.  Notice the vector dimension of 384."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "  id bigserial primary key,\n",
    "  description text,\n",
    "  url text,\n",
    "  split int,\n",
    "  descriptions_embeddings vector(384)\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Embeddings\n",
    "\n",
    "This code will generate embeddings from the descriptions and save the information into the products table.  This will take about 5 minutes to run across 250 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take top 250 for now...\n",
    "top_250_data = data[:250]\n",
    "\n",
    "for x in top_250_data:\n",
    "    r = generate_embeddings(x)\n",
    "    cur.execute(\"INSERT INTO products (url, description, split, descriptions_embeddings) VALUES (%s, %s, %s, %s)\", (r['url'], r['descriptions'][0], r['split'], r['descriptions_embeddings'][0]))\n",
    "    \n",
    "cur.execute(\"\"\"CREATE INDEX ON products\n",
    "  USING ivfflat (descriptions_embeddings vector_l2_ops) WITH (lists = 100);\"\"\")\n",
    "\n",
    "cur.execute(\"VACUUM ANALYZE products;\")\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your Data\n",
    "\n",
    "The following code will encode a query  with a set of descriptions, then use the embeddings to search the listing of products and their embeddings to find matches.  This will be looking for anything with the terms `red`, `sleevless`, `summer` and `wear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "cur = dbconn.cursor()\n",
    "\n",
    "result = encode_sentence(\"red sleeveless summer wear\")\n",
    "\n",
    "cur.execute(\"\"\"SELECT id, url, description, descriptions_embeddings\n",
    "  FROM products\n",
    "  ORDER BY descriptions_embeddings <-> %s limit 2;\"\"\",\n",
    "  (np.array(result),))\n",
    "\n",
    "r = cur.fetchall()\n",
    "urls = []\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "for x in r:\n",
    "    url = x[1].split('?')[0]\n",
    "    urldata = requests.get(url).content\n",
    "    print(\"Product Item Id: \" + str(x[0]))\n",
    "    a = io.imread(url)\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Studio\n",
    "\n",
    "In addition to using the built in transformers via Python, you can also call models that are deployed in Azure.  In this example you will deploy an AI model in Azure Machine Learning and then call it from python. Note that this model is a text generation model and not an embedding model.\n",
    "\n",
    "## Create Workspace\n",
    "\n",
    "- Open the Azure Portal, browse to your lab resource group\n",
    "- In the top search textbox, search for **Azure AI Studio**\n",
    "- Select the **postgres** Azure AI resource\n",
    "- Select the **Launch Azure AI Studio** link\n",
    "- Select **New AI Project**, then select the **postgres** resource\n",
    "- Select **Create an AI Project**\n",
    "- Under **Components**, select **Deployments**\n",
    "- Select **Create->Real-time endpoint**\n",
    "- Select the **gpt2** model and then select **Confirm**\n",
    "- Enter the following:\n",
    "  - Virtual Machine : Select the smallest available image\n",
    "  - Instance count **2**\n",
    "- Select **Deploy**, it may take a couple minutes for the deployment to complete. You will know the deployment is complete with the **Provisioning state** changes to **Succeeded**\n",
    "- Select the **Consume** tab\n",
    "- Copy the **REST endpoint** and **primary key**\n",
    "- Run the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Key and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter your API URL and API Key here\n",
    "uri = 'YOUR_API_URL'\n",
    "api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model endpoint\n",
    "\n",
    "You will need to wait until your deployment is provisioned, this can take 10-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'An unexpected error occurred in scoring script. Check the logs for more info.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#set the sentance  to embed\n",
    "data= {\"input_data\": \"red sleeveless summer wear\"}\n",
    "\n",
    "res = requests.post(uri, headers={'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}, json=data).json()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI Studio\n",
    "\n",
    "## GPT Text Embeddings\n",
    "\n",
    "Now that you have deployed a simple model via Azure Machine Learning Studio, let's look at redo-ing our embeddings using a different embedding model called `text-embedding-ada-002`.\n",
    "\n",
    "This model is not deployed via Azure Machine Learning Studio, but is a part of Azure OpenAI.\n",
    "\n",
    "- Open the Azure Portal\n",
    "- Search for **Azure Open AI**\n",
    "- Under **Resource Management**, select **Keys and Endpoint**\n",
    "- Record the endpoing and the key\n",
    "- Under **Resource Management**, select **Model deployments**\n",
    "- Select **Manage Delopments**\n",
    "- Select **Create new deployment**\n",
    "- Select the **text-embedding-ada-002** model\n",
    "- For the deployment name, type **embeddings**\n",
    "- Select **Create**\n",
    "- Once the model is deployed, run the following cells to regenerate your embeddings. Be sure to replace the endpoint and key with the ones you just recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.azure_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "#get the openai embeddings\n",
    "embedding_model = \"embeddings\" #this is the name of the model deployment in azure open ai (not the type of model)\n",
    "azure_endpoint = \"YOUR_API_URL\"  #https://your-name.openai.azure.com/\n",
    "azure_key = 'YOUR_API_KEY'  \n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "                deployment=embedding_model,\n",
    "                openai_api_base=azure_endpoint,\n",
    "                openai_api_key=azure_key,\n",
    "                openai_api_type=\"azure\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recofigure the methods\n",
    "\n",
    "Change the methods to get the embeddings from Azure Open AI and the text-embedding-ada-002 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_openai_sentence(sentence):\n",
    "    return embeddings.embed_documents([sentence])[0]\n",
    "\n",
    "def encode_openai_sentences(sentences):\n",
    "    return embeddings.embed_documents(sentences)\n",
    "\n",
    "def generate_openai_embeddings(data):\n",
    "    r = {}\n",
    "    r['url'] = data['url']\n",
    "    r['descriptions'] = data['descriptions']\n",
    "    r['split'] = data['split']\n",
    "    vector = encode_openai_sentences(data['descriptions'])\n",
    "    r['descriptions_embeddings'] = vector\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the embeddings table to 1536 dimensions (the hugging face model was only 384)\n",
    "cur = dbconn.cursor()\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS products;\")\n",
    "\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS products(\n",
    "  id bigserial primary key,\n",
    "  description text,\n",
    "  url text,\n",
    "  split int,\n",
    "  descriptions_embeddings vector(1536)\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regenerate the embeddings\n",
    "\n",
    "The next set of code will overwrite the older hugging face embeddings with the newer Open AI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take top 250 for now...\n",
    "top_250_data = data[:250]\n",
    "\n",
    "#query the database\n",
    "cur = dbconn.cursor()\n",
    "\n",
    "for x in top_250_data:\n",
    "    r = generate_openai_embeddings(x)\n",
    "    cur.execute(\"INSERT INTO products (url, description, split, descriptions_embeddings) VALUES (%s, %s, %s, %s)\", (r['url'], r['descriptions'][0], r['split'], r['descriptions_embeddings'][0]))\n",
    "\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your embeddings\n",
    "\n",
    "Re-run the query to see if you get similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the sentence\n",
    "result = encode_openai_sentence(\"red sleeveless summer wear\")\n",
    "\n",
    "cur = dbconn.cursor()\n",
    "\n",
    "#do a search...\n",
    "cur.execute(\"\"\"SELECT id, url, description, descriptions_embeddings\n",
    "  FROM products\n",
    "  ORDER BY descriptions_embeddings <-> %s limit 2;\"\"\",\n",
    "  (np.array(result),))\n",
    "\n",
    "r = cur.fetchall()\n",
    "urls = []\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "for x in r:\n",
    "    url = x[1].split('?')[0]\n",
    "    urldata = requests.get(url).content\n",
    "    print(\"Product Item Id: \" + str(x[0]))\n",
    "    a = io.imread(url)\n",
    "    plt.imshow(a)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
