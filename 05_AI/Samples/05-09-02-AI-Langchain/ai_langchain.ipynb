{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Virtual Environment\n",
    "\n",
    "It is a best practice to create and activate a new Virtual environment when working with lab samples.  This helps to not overwrite the global settings of your main Python install or overwrite packages across your projects.\n",
    "\n",
    "NOTE: These notebooks were tested with Python 3.11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries\n",
    "\n",
    "Install the required libraries and SDKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain \n",
    "!pip install openai \n",
    "!pip install python-environ \n",
    "!pip install psycopg2 \n",
    "!pip install pandas\n",
    "!pip install langchain\n",
    "!pip install langchain_experimental\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a connection string and test the connection. Be sure to replace the `SUFFIX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'wsuser'\n",
    "password = 'Solliance123'\n",
    "host = 'pgsqldevSUFFIXflex14.postgres.database.azure.com'\n",
    "port = '5432'\n",
    "dbname = 'ailabs'\n",
    "\n",
    "connection_string = f'postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}'\n",
    "\n",
    "# Establish a connection to the PostgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=5432,\n",
    "    user=username,\n",
    "    password=password,\n",
    "    database=dbname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sqlalchemy to create a db engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the csv data to the database\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "db_engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to load CSV files and then import them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/calendar.csv')\n",
    "df.to_sql('calendar', db_engine, if_exists='replace', index=False)\n",
    "\n",
    "df = pd.read_csv('./data/listings.csv')\n",
    "df.to_sql('listings', db_engine, if_exists='replace', index=False)\n",
    "\n",
    "df = pd.read_csv('./data/reviews.csv')\n",
    "df.to_sql('reviews', db_engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI Studio\n",
    "\n",
    "## GPT Text Embeddings\n",
    "\n",
    "Now that you have deployed a simple model via Azure Machine Learning Studio, let's look at redo-ing our embeddings using a different embedding model called `text-embedding-ada-002`.\n",
    "\n",
    "This model is not deployed via Azure Machine Learning Studio, but is a part of Azure OpenAI.\n",
    "\n",
    "- Open the Azure Portal\n",
    "- Search for **Azure Open AI**\n",
    "- Under **Resource Management**, select **Keys and Endpoint**\n",
    "- Record the endpoing and the key\n",
    "- Under **Resource Management**, select **Model deployments**\n",
    "- Select **Manage Delopments**\n",
    "- Select **Create new deployment**\n",
    "- Select the **gpt4** model\n",
    "- For the deployment name, type **completions4**\n",
    "- Select **Create**\n",
    "- Once the model is deployed, run the following cells to create a new Chat agent. Be sure to replace the endpoint and key with the ones you just recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "azure_endpoint = \"YOUR_ENDPOINT\"\n",
    "azure_key = 'YOUR_KEY'\n",
    "\n",
    "llm=AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key =azure_key,\n",
    "    openai_api_base = azure_endpoint,\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_type=\"azure\",\n",
    "    model_name=\"gpt4\",\n",
    "    deployment_name=\"completions4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_parsing_errors():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup a SQL agent with a SQLDatabaseToolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql.base import SQLDatabaseChain\n",
    "#from langchain_experimental.sql.base.sql_database import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from langchain import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(connection_string)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=handle_parsing_errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute a query against the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create db chain\n",
    "QUERY = \"\"\"\n",
    "Given an input question, first create a syntactically correct postgresql query to run, then look at the results of the query and return the answer.\n",
    "Use the following format:\n",
    "\n",
    "\"Question\": \"Question here\"\n",
    "\"SQLQuery\": \"SQL Query to run\"\n",
    "\"SQLResult\": \"Result of the SQLQuery\"\n",
    "\"Answer\": \"Final answer here\"\n",
    "\n",
    "\"{question}\"\n",
    "\"\"\"\n",
    "\n",
    "question_text = \"What are the details of the rental that is closest to the Space Needle?\"\n",
    "\n",
    "question = QUERY.format(question=question_text)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    res = agent_executor.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
